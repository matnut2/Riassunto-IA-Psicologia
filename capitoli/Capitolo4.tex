\newpage
\section{Apprendimento Supervisionato}
Tra i concetti principali troviamo:
\begin{itemize}
    \item Classificazione: associare i dati di input a categorie (es: cani, gatti, pesci, uccelli)
    \item Regressione: associare i dati di input a valori continui (es: in base alla classificazione, l'input si classifica sopra o sotto una determinata funzione continua?)
    \item Clustering: scoprire raggruppamenti nei dati di input
\end{itemize}

Nell'apprendimento supervisionato, la rete impara ad associare un dato input ad uno specifico output. L'output desiderato deve essere fornito esplicitamente alla rete durante l'apprendimento e tutti gli esempi per l'apprendimento devono essere etichettati (\textit{labeled data}).\\
Gli algoritmi principali sono: percettrone, regola delta e error back-propagation. Esse vengono applicate tramite classificazione e regressione. Esse sono relazionate con metodi statistici come il \href{https://it.wikipedia.org/wiki/Modello_lineare_generalizzato}{Modello Lineare Generalizzato (GLM)}, la \href{https://it.wikipedia.org/wiki/Regressione_lineare}{regressione} e l'\href{https://it.wikipedia.org/wiki/Analisi_discriminante}{Analisi Discriminante}.

\subsection{La Correzione dell'Errore}
Il \textit{training set} è l'insieme di esempi su cui addestrare la rete, e per i quali possiamo definire input, output e target.\\
L'addestramento avviene presentando un esempio, calcolando l'input sulla base dei parametri attuali (pesi sinaptici), confrontato l'output con il target per determinare lo scostamento per poi modificare i parametri (ottimizzazione) e diminuire lo scostamento.\\
Con il testing si verificano le prestazioni, inclusa la capacità di generalizzare su dati che non sono stati utilizzati per l'addestramento.

\subsection{Il Percettrone}
Il percettrone è il primo modello di rete neurale con pesi sinaptici modificabili da un algoritmo di apprendimento. Sviluppato da Frank Rosenblatt nel 1958, la rete ha \(N\) input che codificano l'esempio presentato con valori \(x_i\) ed un singolo neurone di output che codifica la risposta in modo binario. 
L'output verrà formalmente descritto come:
\[
    y = 
    \begin{cases} 
        1, & \mbox{se } \sum^N_{i=0}w_ix_i \geq 0 \\
        -1, & \mbox{altrimenti}
    \end{cases}
\]
dove \(\theta\) rappresenta la soglia del neurone che serve a definire la posizione del "gradino". Può capitare di non trovare il segno \(\theta\) perché si utilizzano \(w_0\) e \(x_0\) per rappresentare rispettivamente il peso e il valore fisso del bias.

\subsubsection{L'Apprendimento nel Percettrone}
Per ogni esempio presentato, l'output \(y\) viene confrontato con la risposta desiderata (\textit{target}) \(t\) che codifica la classe di appartenenza.
\begin{itemize}
    \item se \(y=t\), allora si procede al prossimo esempio senza modificare nessun peso
    \item se \(y<>t\), allora i pesi sinaptici vengono modificati con \(\Delta w_i=\eta tx_i\) dove \(\eta\) è il learning rate 
\end{itemize}

Da notare che i pesi delle connessioni da cui è arrivato l'input aumentano se il target è \([+1]\) e diminuiscono se il target è \([-1]\). Nel caso di un target binario, è sufficiente sostituire \(t\) con \(t-y\).\\

\subsubsection{Teorema della Convergenza del Percettrone}
Per un qualunque problema linearmente separabile verrà trovata la soluzione in un numero finito di passi.

\subsection{La Regola Delta}
Questa regola viene parzialmente spiegata \href{https://www.youtube.com/watch?v=IHZwWFHWa-w}{qui}, video consigliato dal professore sul Moodle.
Questa si può applicare quando le unità di output hanno una funzione di attivazione continua e differenziabile. Essa permette di descrivere la prestazione con una funzione che misura l'errore della rete (\textit{funzione di errore o funzione di costo}) che si basa sullo scarto quadratico medio tra risposta desiderata ed output effettivo: \[E_w=\sum_\mu \sum_i (t^\mu_i-y^\mu_i)^2\]
L'apprendimento consiste nel minimizzare la funzione di costo E, che dipende unicamente dal valore delle connessioni sinaptiche. Quindi si modificano i pesi nella direzione opposta al gradiente della funzione stessa (\textit{discesa del gradiente}): \[\Delta w_{ij}= - \frac{\delta E}{\delta w_{ij}}\]
La forma finale della regola dipende dal tipo di funzione di attivazione. Nel caso di una funzione lineare otteniamo che il cambiamento dei pesi è dato semplicemente dalla differenza tra target e output moltiplicata per l'attività presinaptica: \[\Delta w_{ij}=\eta (t_i-y_i)x_j\]
Per la funzione sigmoide avremo: \[\eta (t_i-y_i)y_i(1-y_i)x_j\]

\subsubsection{Apprendimento con Regola Delta}
In questo tipo di apprendimento, viene presentata alla rete una configurazione di input, l'attività fluisce alle unità di output. Viene calcolata l'attivazione delle unità di output. La configurazione così ottenuta viene confrontata con la configurazione di output desiderata, viene quindi calcolata la discrepanza tra le due configurazioni e i pesi delle connessioni vengono modificati in modo da ridurre l'errore. La procedura viene eseguita per tutti gli esempi che formano il training set ed ulteriormente ripetuta fino a quando l'errore arriva a 0 o la curva di discesa si stabilizza.

\subsection{Back-Propagation}
Una spiegazione di questa regola si può trovare \href{https://www.youtube.com/watch?v=Ilg3gGewQ5U}{qui}, video consigliato dal professore su Moodle.
L'algoritmo di apprendimento noto come \textit{error back-propagation} è una estensione della regola delta (\textit{regola delta generalizzata}) che permette di addestrare reti multistrato.\\
L'architettura è formata da un qualsiasi numero di strati nascosti (almeno uno) e un qualsiasi tipo di connettività.\\
Il problema viene risolto cercando il modo per calcolare l'errore per le unità nascoste tramite la propagazione all'indietro dell'errore (per l'appunto \textit{error back-propagation}) calcolato per le unità di output attraverso le stesse connessioni che servono per la propagazione dell'attivazione. La propagazione all'indietro dell'errore rende l'algoritmo implausibile dal punto di vista biologico.

\subsection{Apprendimento Batch e Apprendimento Online}
L'apprendimento Batch è caratterizzato da una discesa del gradiente della funzione dell'errore globale. I peso vengono cambiati in base al gradiente calcolato attraverso tutti i pattern.\\
L'apprendimento Online (o a \textit{Mini Batch}) è caratterizzato da una discesa stocastica del gradiente. I pesi vengono cambiati in base al gradiente della funzione dell'errore parziale, calcolato per un singolo esempio.

\subsection{Tasso di Apprendimento}
Il tasso di apprendimento può essere di due tipi: costante o variabile.

\subsubsection{Tasso di Apprendimento Costante}
Il tasso di apprendimento, solitamente indicato con \(\eta\) assume un valore costante. In base alla grandezza di tale numero, otteniamo due risultati distinti:
\begin{itemize}
    \item Costante piccola: apprendimento lento e con minimi locali
    \item Costante grande: apprendimento veloce ma impreciso
\end{itemize}

\subsubsection{Tasso di Apprendimento Variabile}
Il tasso di apprendimento assume un valore variabile in base all'epoca di training o analisi. La formula più utilizzata è: \[\eta = \frac{0.5}{\log{(10+k)}}\] dove \(k\) rappresenta il numero dell'epoca.

\subsubsection{Momentum}
Il momento aggiunge all'aggiornamento del peso sinaptico una frazione del precedente cambiamento di valore. Quando il gradiente dell'errore ha la stessa direzione, il momento aumenta la grandezza del passo che viene fatto verso il minimo. Quando il gradiente cambia direzione, il momento affievolisce il cambiamento.

\subsection{La Generalizzazione}
La generalizzazione è la capacità  di utilizzare in modo appropriato la conoscenza sul dominio quando si incontrano nuovi esempi del problema. Le condizioni necessarie (ma non sufficienti) per ottenere una buona generalizzazione:
\begin{itemize}
    \item Le variabili di input contengono sufficienti informazioni relative al target, in modo che esista una funzione matematica che lega l'output corretto agli input con un determinato grado di accuratezza
    \item Gli esempi per l'addestramento sono in numero sufficientemente grande e sono un campione rappresentativo dell'insieme di casi a cui si vuole generalizzare (popolazione)
\end{itemize}

Le reti multistrato possono apprendere ad approssimare qualunque funzione che lega l'input all'output.\\

\subsubsection{Generalizzazione VS Overfitting}
Nella \textbf{generalizzazione} la produzione di una risposta appropriata a pattern di input non utilizzati per l'addestramento, ovvero un test set indipendente del training set.
\\\\
L'\textbf{overfitting} si verifica quando continua a migliorare la prestazione sui pattern di addestramento ma peggiora le prestazioni in termini di generalizzazione.\\
Questo avviene perché la relazione tra gli elementi non è regolare (ossia ha tante eccezioni) e i dati contengono rumore, quindi la rete apprende anche il rumore nei dati usati per l'addestramento.

\subsection{Evitare l'Overfitting}
Per evitare l'overfitting (migliorando quindi la generalizzazione), bisogna utilizzare reti neurali non troppo potenti perché questo permette di apprendere le regolarità statiche nei dati piuttosto che memorizzare i pattern di training. Questo si può ottenere limitando il numero di unità nascoste,
utilizzando \textbf{\textit{Early Stopping}} ossia quando utilizziamo un set di pattern solo per la verifica di overfitting durante l'apprendimento e fermarlo prima che l'errore sul validation set inizi ad aumentare e utilizzando il \textbf{decadimento dei pesi} (o \textit{weight decay}), ossia facendo in modo che i pesi abbiano la tendenza spontanea a diminuire portando i pesi deboli a tendere verso lo 0 (avendo meno pesi da considerare avremo anche meno parametri, evitando quindi di apprendere anche il rumore nei dati).

\subsection{Training VS Testing}
\paragraph{Training Set}
Esso è un insieme di esempi (\textit{pattern}) per l'addestramento. Sono utilizzati dall'algoritmo di apprendimento per trovare i valori dei pesi delle connessioni.

\paragraph{Validation Set}
Rappresenta un insieme di esempi utilizzati per ottimizzare parametri di apprendimento (\textit{iperparametri}), il numero di unità nascoste e per decidere quando fermare l'apprendimento

\paragraph{Test Set}
Insieme di esempi utilizzati per valutare la performance finale del modello\\
\\
\textit{Perché utilizzare set diversi per validation e test?} Il set di validazione viene utilizzato per selezionare il modello migliore, quindi l'accuratezza sul validation set ha un bias sovrastimato.\\
\textit{Come vanno ripartiti gli esempi?} Bisognerebbe sempre utilizzare quanti più dati possibili per l'addestramento. Se ci sono molti esempio, la suddivisione potrebbe essere, in percentuale, 50-25-25.

\paragraph{Cross-Validazione}
Se i dati non sono sufficienti per ripartirli in due insiemi separati di training e test, è essenziale massimizzare il numero di esempi di training utilizzando la tecnica della \textit{cross-validazione}.\\
Con \textbf{k-fold cross-validation} si intende che il dataset viene diviso in \(k\) parti di uguale numerosità. Ad ogni ciclo di cross-validazione, la \(k\)-esima parte del dataset viene esclusa dal training per essere utilizzati come test. La performance finale è data dalla media trai i risultati di ogni ciclo.

\subsection{Valutazione delle performance}
La valutazione della performance di una rete neurale va fatta sul test set. Esistono molte metriche di performance, anche specifiche per dominio, la distinzione principale tra le metriche di performance è relativa a compiti o di regressione o di classificazione.\\
\paragraph{Regressione} Un compito di regressione implica uno o più output continui. La prestazione si valuta quindi in termini di distanza tra l'output effettivo e quello desiderato, ad esempio utilizzando l'errore quadratico medio o la proporzione di varianza spiegata. Con una singola variabile di output è utile un grafico a dispersione che mostra le predizioni e i valori target.
\paragraph{Classificazione} Un compito di classificazione implica output binari. una valutazione in termini di accuratezza non è sufficiente per stabilire la qualità di un classificatore, ma va considerata la matrice di confusione.

\subsubsection{Matrici di Confusione}
La matrice di confusione restituisce 4 risultati:
\begin{itemize}
    \item TN: True Negative
    \item TP: True Positive
    \item FN: False Negative
    \item FP: False Positive
\end{itemize}
Gli indici di performance sono:
\begin{itemize}
    \item Accuratezza: \(\frac{TN+TP}{TN+TP+FN+FP}\)
    \item Precisione: \(\frac{TP}{TP+FP}\)
    \item Rateo dei True Positive: \(\frac{TP}{TP+FN}\)
    \item Rateo dei False Positive: \(\frac{FP}{TN+FP}\)
\end{itemize}

\subsection{Curva ROC e AUC}
\paragraph{Curca ROC} La curva ROC (\textit{Receiver Operating Characteristic}) per un classificatore viene creata registrando il valore del rateo dei True Positive rispetto a quello dei False Positive al variare di un parametro.Ogni punto sulla curva è ottenuto per un dato valore di parametro del classificatore, spesso la soglia utilizzata per discriminare tra due classi.
\paragraph{Curva AUC} La curva AUC (\textit{Area Under the Curve}) varia tra nell'intervallo \([0,1]\) e rappresenta la performance del classificatore. AUC è invariante alla soglia, ossia misura la qualità delle predizioni del modello indipendentemente dalla soglia di classificazione.

\newpage
\section{Deep Learning Supervisionato}
Nel deep learning supervisionato, la rete neurale ha un numero di strati nascosti maggiore di 1, formando quindi una rete profonda (\textit{deep neural network}).\\
Per il successo del deep learning sono di fondamentale importanza i \textbf{\textit{Big Data}} (accesso a grandi quantità di dati etichettati) e \textbf{\textit{GPU computing}} (enorme potenza di calcolo parallelo su schede di processori grafici).
\subsection{Il Problema del Vanishing Gradient}
Se aggiungiamo molti strati nascosti, il segnale di errore deve passare per molti livelli di retro-propagazione prima di giungere alle connessioni più vicine all'input. Questo fenomeno è particolarmente problematico con la funzione di attivazione sigmoidea, la quale tende a saturare quando la somma pesata degli input è troppo grande o troppo piccola, infatti la derivata tende a zero nella zona di saturazione e di conseguenza il gradiente svanisce nel giro di pochi passi di retro-propagazione.
\subsubsection{Gli Sviluppi che hanno Consentito la Rivoluzione del Deep Learing}
Miglioramento degli algoritmi:
\begin{itemize}
    \item Inizializzazione smart (e non randomica) dei pesi iniziali
    \item Learning rate adattivo in base al gradiente
    \item Utilizzo di reti di grandi dimensioni combinate con regolarizzatori efficaci (sparsità + decadimento dei pesi + \textit{dropout})
    \item Ottimizzatori del 2° ordine
    \item Funzione di attivazione che non satura il gradiente (\textit{Rectified Linear Unit - RELU}).
\end{itemize}

Oltre a questo:
\begin{itemize}
    \item Disponibilità di enormi training set digitali
    \item Aumento delle prestazioni di calcolo
    \item Architetture convoluzionali
\end{itemize}

\subsection{Reti Neurali Convoluzionali}
La \textit{Convolutional Neural Network - CNN} è una rete profonda che include almeno uno strato convoluzionale in cui i neuroni nascosti non sono interamente connessi con lo strato precedente ma hanno campi recettivi locali. Solitamente questo strato è seguito da uno strato di \textit{pooling} che serve per ridurre la dimensionalità ed enfatizzare le caratteristiche più salienti.\\
Nella parte più profonda della rete è inserito almeno uno strato nascosto standard interamente connesso con quello precedente. L'ultimo strato nascosto interamente connesso attiva lo strato di output.
\subsubsection{Lo Strato Convoluzionale}
Ogni neurone nascosto dello strato convoluzionale ha un campo recettivo locale che codifica una specifica \textit{feature} chiamata anche \textit{kernel} o filtro.\\
Il numero di neuroni definisce quante \textit{features} verranno rappresentate in ciascun livello.\\
A differenza delle reti multi-strato standard, ciascun filtro è applicato all'intera immagine attraverso un'operazione di convoluzione, ed è come avere più copie dello stesso neurone, in quanto utilizziamo lo stesso insieme di pesi per processare diverse porzioni dell'immagine in input.
\subsubsection{Iperparametri di CNN}
Gli iperparametri di una \textit{CNN} sono:
\begin{itemize}
    \item Numero di neuroni nascosti: specifica quanti filtri usare in ciascun layer
    \item Dimensioni del kernel: definisce il campo recettivo del filtro
    \item Stride: dimensione del passo di spostamento del filtro (\textit{overlap})
    \item Padding: per mantenere invariata la dimensione dell'immagine, si imposta un bordo aggiuntivo con valori costanti (e solitamente inizializzati a 0)
\end{itemize}

\subsubsection{Lo Strato di Pooling}
Lo strato di pooling viene inserito dopo uno strato convoluzionale per ridurre la dimensione dell'immagine. Questo riduce il numero di parametri, controllando l'overfitting e promuovendo l'invarianza.

\subsection{La Dimensione Temporale}
L'informazione in input può arrivare al sistema neurale in modo sequenziale, e può quindi possedere una struttura temporale, per questo anche l'output deve possedere una natura sequenziale.
Solitamente questo si applica per problemi di:
\begin{itemize}
    \item Riconoscimento del parlato
    \item Riconoscimento di azioni
    \item Predizione della dinamica in oggetti in movimento
    \item Generazione di testo o musica
    \item Predizione di serie storiche
\end{itemize}

In una classica rete multistrato, l'output \(O(t)\) al tempo \(t\) dipende solo dall'input corrente \(I(t)\), quindi non può apprendere dipendenze temporali.\\
Una possibile soluzione consiste nel trasformare il tempo in spazio, ossia presentiamo come input alcuni elementi della sequenza \(S\) in una \textit{finestra temporale} \(W^T(t)\) che si sposta sopra \(S\), ossia:
\[W^T(t)=[S_t, S_{t+1}, ... , S_{t+T}]\]
Qui però sorgono due problemi:
\begin{enumerate}
    \item I neuroni di input vengono replicati per ogni elemento rappresentato nella finestra
    \item Visibilità limitata della grandezza della finestra
\end{enumerate}
\subsection{Le Reti Parzialmente Ricorrenti}
Un modo semplice di elaborare strutture temporali consiste nell'aggiungere connessioni ricorrenti che forniscano un input ricorrente proveniente dallo stesso strato o da strati superiori. In questo modo le risposte delle reti dipendono dal classico input \textit{feed-forward} derivante dagli strati inferiori e dagli input degli strati precedenti.\\
\subsubsection{Addestramento delle Reti Ricorrenti}
Le reti parzialmente ricorrenti si possono addestrare con l'algoritmo di \textit{back-propagation} dato che la loro struttura temporale può essere srotolata per trasformarla in una struttura spaziale.

\subsection{Long-Short Term Memory Network- LSTM}
Le \textit{SRN - Reti di Hellman} hanno una memoria a breve termine e quindi non riescono ad apprendere dipendenze temporali lontane nella sequenza di input. Questo problema viene risolto nelle reti \textit{LSTM} in cui lo strato nascosto è formato da unità \textit{LSTM} che hanno una struttura più complessa rispetto ai tipici neuroni nascosti.\\
Le unità \textit{LSTM} operano attraverso delle porte che definiscono se l'informazione vada mantenuta nella memoria temporanea e quanto avanti nel tempo dovrebbe essere propagata. Esistono tre tipi di porte, ossia:
\begin{itemize}
    \item Input Gate: lascia entrare l'input nella cella di memoria
    \item Output Gate: lascia uscire il valore corrente dalla cella di memoria
    \item Forget Gate: resetta il valore corrente nella cella di Memoria
\end{itemize}

Da ricordare inoltre che ogni gate ha il suo insieme di pesi sinaptici.

\subsection{Deep Recurrent Neural Network (RNN) per le sequenze}
Questo rappresenta un Deep network con strati nascosti multipli di unità \textit{LSTM}. L'input è un elemento della sequenza, mentre l'output è l'elemento successivo della sequenza. La predizione può essere a step singolo (la rete viene testata sulla predizione del prossimo elemento) o multi step (la predizione del prossimo elemento è utilizzata come input così da ottenere una sequenza di predizioni successive).

\subsection{Word Embeddings}
La modellizzazione di sequenze per l'elaborazione del linguaggio naturale è più efficiente al livello della parola. Questo richiede di precodificare le singole parole con vettori di lunghezza fissa usando algoritmi di embedding.
Normalmente questi algoritmi presentano le seguenti proprietà:
\begin{itemize}
    \item Gli embeddings preservano relazioni semantiche (parole vicine nello spazio vettoriale hanno un significato simile)
    \item Composizionalità: operazioni lineari sui vettori producono risultati coerenti.
\end{itemize}
